services:
  postgres:
    image: postgres:15
    container_name: dinelike-postgres
    environment:
      POSTGRES_DB: dinelike
      POSTGRES_USER: dinelike
      POSTGRES_PASSWORD: dinelike123
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./sql:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U dinelike"]
      interval: 10s
      timeout: 5s
      retries: 5

  init-db:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: dinelike-init-db
    command: python -c "from src.services.init_db import main; main()"
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: dinelike
      DB_USER: dinelike
      DB_PASSWORD: dinelike123
    volumes:
      - ./src:/app/src:ro
      - ./data:/app/data:ro

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: dinelike-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: dinelike-kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'

  api:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: dinelike-api
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_started
    environment:
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: dinelike
      DB_USER: dinelike
      DB_PASSWORD: dinelike123
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      KAFKA_TOPIC: quiz_submissions
    volumes:
      - ./src:/app/src:ro

  consumer:
    build:
      context: .
      dockerfile: Dockerfile.consumer
    container_name: dinelike-consumer
    depends_on:
      - postgres
      - kafka
    restart: on-failure
    command: sh -c "sleep 30 && python -m src.services.kafka_consumer"
    environment:
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: dinelike
      DB_USER: dinelike
      DB_PASSWORD: dinelike123
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
    volumes:
      - ./src:/app/src:ro

  frontend:
    image: node:20
    container_name: dinelike-frontend
    working_dir: /app
    command: sh -c "npm install && npm run dev -- --host"
    ports:
      - "5173:5173"
    volumes:
      - ./frontend:/app
    depends_on:
      - api

  # Airflow for orchestration (optional - use profile to start)
  airflow:
    image: apache/airflow:2.7.3-python3.11
    container_name: dinelike-airflow
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://dinelike:dinelike123@postgres/dinelike
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=dinelike
      - DB_USER=dinelike
      - DB_PASSWORD=dinelike123
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
    ports:
      - "8080:8080"
    entrypoint: /bin/bash
    command:
      - -c
      - |
        pip install psycopg2-binary
        airflow db migrate
        airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com || true
        airflow webserver -p 8080 &
        exec airflow scheduler
    depends_on:
      postgres:
        condition: service_healthy
    profiles:
      - with-airflow

volumes:
  postgres_data:
